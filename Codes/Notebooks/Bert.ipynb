{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74685985-2740-4250-9e9a-207d411e3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets scikit-learn dill\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a43bb-84b9-478c-a530-a7d46dcbaccf",
   "metadata": {},
   "source": [
    "### Chargement & nettoyage du texte + concatÃ©nation avec keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23135e33-599d-4bc8-b416-53d392b3db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement\n",
    "data = pd.read_csv(r'C:\\Users\\HP\\Desktop\\ISEP2\\Semestre2\\Machine Learning\\Projet\\Codes\\Notebooks\\tweets.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1613cda2-ccb5-4634-a6d1-d1ed929cf1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11365</th>\n",
       "      <td>11365</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Blue State in a red sea</td>\n",
       "      <td>Media should have warned us well in advance. T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11366</th>\n",
       "      <td>11366</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>arohaonces</td>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>11367</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>ðŸ‡µðŸ‡­</td>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11368</th>\n",
       "      <td>11368</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>auroraborealis</td>\n",
       "      <td>ok who remember \"outcast\" nd the \"dora\" au?? T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>11369</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jake Corway wrecked while running 14th at IRP.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11370 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  keyword                 location  \\\n",
       "0          0   ablaze                      NaN   \n",
       "1          1   ablaze                      NaN   \n",
       "2          2   ablaze            New York City   \n",
       "3          3   ablaze           Morgantown, WV   \n",
       "4          4   ablaze                      NaN   \n",
       "...      ...      ...                      ...   \n",
       "11365  11365  wrecked  Blue State in a red sea   \n",
       "11366  11366  wrecked               arohaonces   \n",
       "11367  11367  wrecked                       ðŸ‡µðŸ‡­   \n",
       "11368  11368  wrecked           auroraborealis   \n",
       "11369  11369  wrecked                      NaN   \n",
       "\n",
       "                                                    text  target  \n",
       "0      Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1      Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2      Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3      Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4      \"Lord Jesus, your love brings freedom and pard...       0  \n",
       "...                                                  ...     ...  \n",
       "11365  Media should have warned us well in advance. T...       0  \n",
       "11366  i feel directly attacked ðŸ’€ i consider moonbin ...       0  \n",
       "11367  i feel directly attacked ðŸ’€ i consider moonbin ...       0  \n",
       "11368  ok who remember \"outcast\" nd the \"dora\" au?? T...       0  \n",
       "11369     Jake Corway wrecked while running 14th at IRP.       1  \n",
       "\n",
       "[11370 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f0e8a-c6fa-4eff-bba2-d14f3d91897e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8773f8d-7c76-4a0f-b0da-016cd66abc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nettoyage\n",
    "def clean_tweet(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r\"@\\w+\", '', text)\n",
    "    text = re.sub(r\"#\", '', text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "    text = re.sub(r\"\\d+\", '', text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "data[\"clean_text\"] = data[\"text\"].apply(clean_tweet)\n",
    "data[\"keyword\"] = data[\"keyword\"].fillna(\"unknown\").str.lower()\n",
    "\n",
    "# Fusion keyword + texte avec un sÃ©parateur [SEP]\n",
    "data[\"bert_input\"] = data[\"keyword\"] + \" \" + data[\"clean_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966eb0be-4b32-4a70-a8bf-6e10e2eb5801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>bert_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "      <td>communal violence in bhainsa telangana stones ...</td>\n",
       "      <td>ablaze communal violence in bhainsa telangana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "      <td>telangana section has been imposed in bhainsa ...</td>\n",
       "      <td>ablaze telangana section has been imposed in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "      <td>arsonist sets cars ablaze at dealership</td>\n",
       "      <td>ablaze arsonist sets cars ablaze at dealership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "      <td>arsonist sets cars ablaze at dealership</td>\n",
       "      <td>ablaze arsonist sets cars ablaze at dealership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "      <td>lord jesus your love brings freedom and pardon...</td>\n",
       "      <td>ablaze lord jesus your love brings freedom and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11365</th>\n",
       "      <td>11365</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Blue State in a red sea</td>\n",
       "      <td>Media should have warned us well in advance. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>media should have warned us well in advance th...</td>\n",
       "      <td>wrecked media should have warned us well in ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11366</th>\n",
       "      <td>11366</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>arohaonces</td>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i feel directly attacked i consider moonbin am...</td>\n",
       "      <td>wrecked i feel directly attacked i consider mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>11367</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>ðŸ‡µðŸ‡­</td>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i feel directly attacked i consider moonbin am...</td>\n",
       "      <td>wrecked i feel directly attacked i consider mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11368</th>\n",
       "      <td>11368</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>auroraborealis</td>\n",
       "      <td>ok who remember \"outcast\" nd the \"dora\" au?? T...</td>\n",
       "      <td>0</td>\n",
       "      <td>ok who remember outcast nd the dora au those a...</td>\n",
       "      <td>wrecked ok who remember outcast nd the dora au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>11369</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jake Corway wrecked while running 14th at IRP.</td>\n",
       "      <td>1</td>\n",
       "      <td>jake corway wrecked while running th at irp</td>\n",
       "      <td>wrecked jake corway wrecked while running th a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11370 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  keyword                 location  \\\n",
       "0          0   ablaze                      NaN   \n",
       "1          1   ablaze                      NaN   \n",
       "2          2   ablaze            New York City   \n",
       "3          3   ablaze           Morgantown, WV   \n",
       "4          4   ablaze                      NaN   \n",
       "...      ...      ...                      ...   \n",
       "11365  11365  wrecked  Blue State in a red sea   \n",
       "11366  11366  wrecked               arohaonces   \n",
       "11367  11367  wrecked                       ðŸ‡µðŸ‡­   \n",
       "11368  11368  wrecked           auroraborealis   \n",
       "11369  11369  wrecked                      NaN   \n",
       "\n",
       "                                                    text  target  \\\n",
       "0      Communal violence in Bhainsa, Telangana. \"Ston...       1   \n",
       "1      Telangana: Section 144 has been imposed in Bha...       1   \n",
       "2      Arsonist sets cars ablaze at dealership https:...       1   \n",
       "3      Arsonist sets cars ablaze at dealership https:...       1   \n",
       "4      \"Lord Jesus, your love brings freedom and pard...       0   \n",
       "...                                                  ...     ...   \n",
       "11365  Media should have warned us well in advance. T...       0   \n",
       "11366  i feel directly attacked ðŸ’€ i consider moonbin ...       0   \n",
       "11367  i feel directly attacked ðŸ’€ i consider moonbin ...       0   \n",
       "11368  ok who remember \"outcast\" nd the \"dora\" au?? T...       0   \n",
       "11369     Jake Corway wrecked while running 14th at IRP.       1   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0      communal violence in bhainsa telangana stones ...   \n",
       "1      telangana section has been imposed in bhainsa ...   \n",
       "2                arsonist sets cars ablaze at dealership   \n",
       "3                arsonist sets cars ablaze at dealership   \n",
       "4      lord jesus your love brings freedom and pardon...   \n",
       "...                                                  ...   \n",
       "11365  media should have warned us well in advance th...   \n",
       "11366  i feel directly attacked i consider moonbin am...   \n",
       "11367  i feel directly attacked i consider moonbin am...   \n",
       "11368  ok who remember outcast nd the dora au those a...   \n",
       "11369        jake corway wrecked while running th at irp   \n",
       "\n",
       "                                              bert_input  \n",
       "0      ablaze communal violence in bhainsa telangana ...  \n",
       "1      ablaze telangana section has been imposed in b...  \n",
       "2         ablaze arsonist sets cars ablaze at dealership  \n",
       "3         ablaze arsonist sets cars ablaze at dealership  \n",
       "4      ablaze lord jesus your love brings freedom and...  \n",
       "...                                                  ...  \n",
       "11365  wrecked media should have warned us well in ad...  \n",
       "11366  wrecked i feel directly attacked i consider mo...  \n",
       "11367  wrecked i feel directly attacked i consider mo...  \n",
       "11368  wrecked ok who remember outcast nd the dora au...  \n",
       "11369  wrecked jake corway wrecked while running th a...  \n",
       "\n",
       "[11370 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f90c8-5b2e-4417-8a3c-d283ff69b79c",
   "metadata": {},
   "source": [
    "### Tokenisation et prÃ©paration du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e750db09-bb25-4409-ad75-25b1ac2b8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730ae4ab-e8e4-444d-aca1-9e516224c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data[\"clean_text\"].tolist(), \n",
    "    data[\"target\"].tolist(), \n",
    "    test_size=0.2, \n",
    "    stratify=data[\"target\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede4479-1cd8-4fe1-b4bc-58297ffbbcb0",
   "metadata": {},
   "source": [
    "### CrÃ©ation du Dataset PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e1712-365b-4551-b19a-9c0c17cae356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4bc93f-83d0-4595-8f4c-f7386f17e463",
   "metadata": {},
   "source": [
    " ### Initialisation du modÃ¨le BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667e473b-f820-449c-8739-7a584b986d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042d166e-f759-4a67-98ce-38bbb8c45829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d444e9eb29fd4acba835660bb6650722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67deab-4c95-47f9-ad97-3fb897961c54",
   "metadata": {},
   "source": [
    "### EntraÃ®nement du modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ffbb121-6ce5-4abc-bc08-25705b384a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1 â€” Loss moyenne : 0.2766\n",
      "âœ… Epoch 2 â€” Loss moyenne : 0.1549\n",
      "âœ… Epoch 3 â€” Loss moyenne : 0.0681\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):  # augmente si besoin\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"âœ… Epoch {epoch + 1} â€” Loss moyenne : {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d1770-d2d6-4b68-96de-5b996cc2410d",
   "metadata": {},
   "source": [
    "### Ã‰valuation : AUC + toutes les mÃ©triques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c905f583-bff2-4190-84a3-d9e5ef50fbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ RÃ©sultats :\n",
      "Accuracy  : 0.9063\n",
      "Precision : 0.7134\n",
      "Recall    : 0.8298\n",
      "F1-score  : 0.7672\n",
      "AUC       : 0.9431\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds)\n",
    "rec = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "print(\"\\nðŸ“ˆ RÃ©sultats :\")\n",
    "print(f\"Accuracy  : {acc:.4f}\")\n",
    "print(f\"Precision : {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")\n",
    "print(f\"F1-score  : {f1:.4f}\")\n",
    "print(f\"AUC       : {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199f358-3f6c-41a9-9f2e-e7c5a4a499be",
   "metadata": {},
   "source": [
    "### Sauvegarde du modÃ¨le avec dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "739c3834-0382-440f-ad21-4ca3b94f7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"bert_model.dill\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d3bba0-736c-49c7-b896-e48caf231049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sauvegarde du modÃ¨le complet (BERT + Tokenizer) dans : C:\\Users\\HP\\Desktop\\ISEP2\\Semestre2\\Machine Learning\\Projet\\Models\\bert_full_model_optimized.dill\n",
      " ModÃ¨le complet sauvegardÃ© avec succÃ¨s !\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "# DÃ©finir le rÃ©pertoire et le nom du fichier\n",
    "MODEL_DIR = r'C:\\Users\\HP\\Desktop\\ISEP2\\Semestre2\\Machine Learning\\Projet\\Models'\n",
    "model_path_name = Path(MODEL_DIR, \"bert_full_model_optimized.dill\")\n",
    "\n",
    "# VÃ©rifier que le dossier existe, sinon le crÃ©er\n",
    "Path(MODEL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CrÃ©er un objet qui contient les deux (modÃ¨le + tokenizer)\n",
    "bert_complete_model = {\n",
    "    \"model\": model,\n",
    "    \"tokenizer\": tokenizer\n",
    "}\n",
    "\n",
    "# Sauvegarde dans un seul fichier\n",
    "print(f\" Sauvegarde du modÃ¨le complet (BERT + Tokenizer) dans : {model_path_name}\")\n",
    "with open(model_path_name, \"wb\") as fp:\n",
    "    dill.dump(bert_complete_model, fp)\n",
    "\n",
    "print(f\" ModÃ¨le complet sauvegardÃ© avec succÃ¨s !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c18989-8ac1-4984-8f60-cfb9c9ba1dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
